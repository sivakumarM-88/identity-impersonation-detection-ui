Gitclone the following url

Pip install –r requirements.txt

Streamlilt run voiceapp.py/emotapp.py/imageapp.py

Upload respective wav/mp3 and wait for result



Challenge Given: The primary objective of this challenge is to develop effective countermeasures against identity personification using AI-generated voice prints. This challenge seeks to address the growing threat of voice-based fraud and protect individuals and organizations from unauthorized access and impersonation
Specific problems to solve: 1) Classify AI generated Vs Real Audios 
2)Identify emotion/different sounds/annotations etc

Approach used :To distinguish between real and deep fake audio, feature extraction is essential.For this CNN-DNN model architecture can be used .  MFCCs, spectrogram pictures, or a mix of the two can be utilized as the model’s input features. These features capture the frequency and temporal aspects of the audio, aiding the model in identifying anomalies.
